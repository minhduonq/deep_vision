# Deep Vision - Quick Start Guide

## üöÄ B·∫Øt ƒë·∫ßu nhanh (Quick Start)

H∆∞·ªõng d·∫´n n√†y gi√∫p b·∫°n setup v√† ch·∫°y Deep Vision project nhanh nh·∫•t c√≥ th·ªÉ.

## Y√™u c·∫ßu h·ªá th·ªëng (Prerequisites)

- **Python**: 3.10 ho·∫∑c cao h∆°n
- **GPU**: NVIDIA GPU v·ªõi CUDA (t√πy ch·ªçn, nh∆∞ng khuy·∫øn ngh·ªã)
- **RAM**: T·ªëi thi·ªÉu 8GB (khuy·∫øn ngh·ªã 16GB)
- **Storage**: ~20GB cho models v√† dependencies

## B∆∞·ªõc 1: Clone v√† Setup Environment

```powershell
# T·∫°o virtual environment
python -m venv venv

# Activate virtual environment (PowerShell)
.\venv\Scripts\Activate.ps1

# Ho·∫∑c n·∫øu b·ªã l·ªói execution policy
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
.\venv\Scripts\Activate.ps1

# Upgrade pip
python -m pip install --upgrade pip
```

## B∆∞·ªõc 2: C√†i ƒë·∫∑t Dependencies

### C√°ch 1: GPU Setup (khuy·∫øn ngh·ªã n·∫øu c√≥ NVIDIA GPU)

```powershell
# C√†i PyTorch v·ªõi CUDA support
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# C√†i c√°c packages c√≤n l·∫°i
pip install -r requirements.txt
```

### C√°ch 2: CPU-Only Setup

```powershell
# S·ª≠a trong requirements.txt:
# torch==2.1.2 th√†nh torch==2.1.2+cpu
# torchvision==0.16.2 th√†nh torchvision==0.16.2+cpu

pip install -r requirements.txt
```

### C√°ch 3: API-Only (kh√¥ng c·∫ßn GPU m·∫°nh)

```powershell
# Ch·ªâ c√†i dependencies c∆° b·∫£n
pip install fastapi uvicorn python-multipart pydantic
pip install langchain langgraph langchain-openai
pip install opencv-python pillow numpy
pip install replicate httpx streamlit
```

## B∆∞·ªõc 3: C·∫•u h√¨nh Environment Variables

```powershell
# Copy file .env.example
copy .env.example .env

# M·ªü .env v√† ƒëi·ªÅn API keys c·ªßa b·∫°n
notepad .env
```

**C·∫ßn thi·∫øt ph·∫£i c√≥:**
- `OPENAI_API_KEY` ho·∫∑c `ANTHROPIC_API_KEY` (cho LLM agents)

**T√πy ch·ªçn (n·∫øu d√πng API thay v√¨ local models):**
- `REPLICATE_API_TOKEN` (khuy·∫øn ngh·ªã - d·ªÖ setup nh·∫•t)
- `STABILITY_API_KEY` (cho Stable Diffusion)
- `HUGGINGFACE_API_TOKEN` (cho HF models)

## B∆∞·ªõc 4: T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c

```powershell
# T·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
New-Item -ItemType Directory -Force -Path backend,backend\api,backend\agents,backend\models,backend\core,frontend,uploads,outputs,models,logs
```

## B∆∞·ªõc 5: T·∫°o Backend c∆° b·∫£n

T·∫°o file `backend/api/main.py`:

```python
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
import uvicorn
import os
from pathlib import Path

app = FastAPI(title="Deep Vision API", version="0.1.0")

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
Path("uploads").mkdir(exist_ok=True)
Path("outputs").mkdir(exist_ok=True)

@app.get("/")
async def root():
    return {"message": "Deep Vision API is running!", "version": "0.1.0"}

@app.get("/api/v1/health")
async def health_check():
    return {
        "status": "healthy",
        "gpu_available": False,  # TODO: implement GPU check
        "models_loaded": []
    }

@app.post("/api/v1/enhance")
async def enhance_image(file: UploadFile = File(...)):
    """Endpoint ƒë·ªÉ x·ª≠ l√Ω enhancement tasks"""
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    # TODO: Implement enhancement logic
    return {
        "task_id": "temp_123",
        "status": "processing",
        "message": "Enhancement task created"
    }

@app.post("/api/v1/generate")
async def generate_image(prompt: str):
    """Endpoint ƒë·ªÉ generate ·∫£nh t·ª´ prompt"""
    if not prompt:
        raise HTTPException(status_code=400, detail="Prompt is required")
    
    # TODO: Implement generation logic
    return {
        "task_id": "temp_456",
        "status": "processing",
        "message": "Generation task created"
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
```

## B∆∞·ªõc 6: Ch·∫°y Backend

```powershell
# C√°ch 1: Ch·∫°y tr·ª±c ti·∫øp (code ƒë√£ s·ª≠a ƒë·ªÉ support)
python backend/api/main.py

# C√°ch 2: D√πng module syntax (khuy·∫øn ngh·ªã)
python -m backend.api.main

# C√°ch 3: D√πng uvicorn tr·ª±c ti·∫øp
uvicorn backend.api.main:app --reload
```

M·ªü browser v√† truy c·∫≠p:
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## B∆∞·ªõc 7: T·∫°o Frontend ƒë∆°n gi·∫£n (Streamlit)

T·∫°o file `frontend/streamlit_app.py`:

```python
import streamlit as st
import requests
from PIL import Image
import io

st.set_page_config(page_title="Deep Vision", page_icon="üé®", layout="wide")

st.title("üé® Deep Vision - AI Image Processing")

API_BASE_URL = "http://localhost:8000/api/v1"

# Sidebar
st.sidebar.header("Options")
task_type = st.sidebar.selectbox(
    "Select Task",
    ["Image Enhancement", "Image Generation"]
)

if task_type == "Image Enhancement":
    st.header("üì∏ Image Enhancement")
    
    enhancement_type = st.selectbox(
        "Enhancement Type",
        ["Deblur", "Remove Object", "Beauty Enhancement"]
    )
    
    uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])
    
    if uploaded_file:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Original Image")
            image = Image.open(uploaded_file)
            st.image(image, use_column_width=True)
        
        with col2:
            st.subheader("Enhanced Image")
            if st.button("Process Image"):
                with st.spinner("Processing..."):
                    # TODO: Call API
                    st.info("Feature coming soon!")

else:  # Image Generation
    st.header("üé® Image Generation")
    
    prompt = st.text_area("Enter your prompt", height=100)
    
    col1, col2 = st.columns([1, 2])
    with col1:
        negative_prompt = st.text_input("Negative prompt (optional)")
        num_images = st.slider("Number of images", 1, 4, 1)
    
    if st.button("Generate Image"):
        if prompt:
            with st.spinner("Generating..."):
                # TODO: Call API
                st.info("Feature coming soon!")
        else:
            st.warning("Please enter a prompt")

# Footer
st.sidebar.markdown("---")
st.sidebar.info("Deep Vision v0.1.0")
```

## B∆∞·ªõc 8: Ch·∫°y Frontend

```powershell
# M·ªü terminal m·ªõi (gi·ªØ backend ƒëang ch·∫°y)
streamlit run frontend/streamlit_app.py
```

M·ªü browser v√† truy c·∫≠p: http://localhost:8501

## üéØ Chi·∫øn l∆∞·ª£c tri·ªÉn khai theo giai ƒëo·∫°n

### Giai ƒëo·∫°n 1: API-First (Tu·∫ßn 1) - KHUY·∫æN NGH·ªä B·∫ÆT ƒê·∫¶U T·∫†I ƒê√ÇY

**∆Øu ƒëi·ªÉm:**
- Kh√¥ng c·∫ßn GPU m·∫°nh
- Chi ph√≠ th·∫•p (pay-as-you-go)
- Deploy nhanh
- T·∫≠p trung v√†o logic agents

**Setup:**
```python
# S·ª≠ d·ª•ng Replicate API cho t·∫•t c·∫£ models
import replicate

# Deblur
output = replicate.run(
    "jingyunliang/swinir:...",
    input={"image": image_url}
)

# Generation
output = replicate.run(
    "stability-ai/sdxl:...",
    input={"prompt": prompt}
)
```

### Giai ƒëo·∫°n 2: Hybrid (Tu·∫ßn 2-3)

**Khi n√†o chuy·ªÉn:**
- Khi c√≥ nhi·ªÅu users
- Chi ph√≠ API cao
- C·∫ßn t√πy ch·ªânh models

**Setup:**
```python
# Lightweight models ‚Üí local
# Heavy models ‚Üí API

if model_size < threshold:
    result = local_inference(image)
else:
    result = api_inference(image)
```

### Giai ƒëo·∫°n 3: Full Local (Tu·∫ßn 4+)

**Khi n√†o chuy·ªÉn:**
- C√≥ GPU t·ªët (RTX 3060+)
- Traffic ·ªïn ƒë·ªãnh
- C·∫ßn privacy/offline

## ‚ö° Optimization Tips cho GPU h·∫°n ch·∫ø

### 1. S·ª≠ d·ª•ng Model nh·ªè g·ªçn

```python
# Thay v√¨ SD 1.5 ho·∫∑c SDXL
model = "stabilityai/stable-diffusion-2-1-base"  # Nh·∫π h∆°n

# Ho·∫∑c d√πng LCM cho faster inference
from diffusers import LCMScheduler
pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)
```

### 2. Gi·∫£m resolution

```python
# Trong .env
DEFAULT_IMAGE_SIZE=512  # Thay v√¨ 1024
MAX_IMAGE_SIZE=768
```

### 3. Enable optimizations

```python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,  # Gi·∫£m 50% VRAM
    use_safetensors=True
)

# Memory optimizations
pipe.enable_attention_slicing()  # Gi·∫£m VRAM usage
pipe.enable_vae_slicing()
if torch.cuda.is_available():
    pipe.enable_xformers_memory_efficient_attention()
```

### 4. Offload to CPU

```python
# Sequential CPU offload (ti·∫øt ki·ªám VRAM nh·∫•t nh∆∞ng ch·∫≠m h∆°n)
pipe.enable_sequential_cpu_offload()

# Model CPU offload (c√¢n b·∫±ng)
pipe.enable_model_cpu_offload()
```

## üìä So s√°nh c√°c approach

| Approach | GPU Requirement | Cost | Speed | Customization |
|----------|----------------|------|-------|---------------|
| **API-Only** | None | Medium | Fast | Low |
| **Hybrid** | 4GB VRAM | Low-Medium | Medium | Medium |
| **Full Local** | 8GB+ VRAM | Low | Slow-Medium | High |

## üêõ Troubleshooting

### L·ªói CUDA Out of Memory

```python
# Gi·∫£m batch size
MAX_BATCH_SIZE=1

# Gi·∫£m resolution
image = image.resize((512, 512))

# Clear cache
import torch
torch.cuda.empty_cache()
```

### L·ªói Import

```powershell
# Reinstall v·ªõi --force
pip install --force-reinstall transformers diffusers
```

### L·ªói PowerShell Execution Policy

```powershell
# Run as Administrator
Set-ExecutionPolicy RemoteSigned -Scope CurrentUser
```

## üìù Next Steps

1. ‚úÖ **Setup xong m√¥i tr∆∞·ªùng** ‚Üí Ch·∫°y th·ª≠ basic API
2. üîë **L·∫•y API keys** ‚Üí OpenAI/Anthropic (cho agents), Replicate (cho models)
3. ü§ñ **Implement agents** ‚Üí B·∫Øt ƒë·∫ßu v·ªõi Task Analyzer
4. üé® **T√≠ch h·ª£p first model** ‚Üí Ch·ªçn 1 task (deblur ho·∫∑c generation)
5. üß™ **Test end-to-end** ‚Üí T·ª´ upload ·∫£nh ƒë·∫øn nh·∫≠n k·∫øt qu·∫£
6. üéØ **Expand features** ‚Üí Th√™m c√°c tasks kh√°c
7. üöÄ **Optimize** ‚Üí Based on usage patterns

## üí° Khuy·∫øn ngh·ªã c·ªßa t√¥i

**Cho b·∫°n (GPU h·∫°n ch·∫ø):**

1. **Week 1-2**: D√πng 100% API
   - Focus v√†o logic agents v√† workflow
   - D√πng Replicate cho t·∫•t c·∫£ CV tasks
   - D√πng OpenAI/Anthropic cho LLM agents

2. **Week 3**: Test hybrid
   - Ch·∫°y preprocessing (resize, format conversion) local
   - Heavy inference qua API

3. **Week 4+**: Quy·∫øt ƒë·ªãnh d·ª±a tr√™n:
   - S·ªë l∆∞·ª£ng users
   - Chi ph√≠ API
   - GPU availability

**Start simple, scale smart! üöÄ**

## üÜò C·∫ßn h·ªó tr·ª£?

- ƒê·ªçc `ARCHITECTURE.md` cho technical details
- Check `README.md` cho overview
- Xem examples trong `examples/` folder (coming soon)

Good luck! üéâ
